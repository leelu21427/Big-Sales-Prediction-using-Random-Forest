# -*- coding: utf-8 -*-
"""Big_Sales_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dVS2xjxQ3BO5-OHXPeI2iMDbHAOEolL6

# **Big Sales Prediction using Random Forest Algorithm**

**Objective**
The objective of big sales prediction, typically within the context of businesses or retail, is to forecast future sales volumes accurately. This prediction is crucial for various reasons:

**Inventory Management:** Accurate sales predictions help businesses optimize their inventory levels. By forecasting demand, they can ensure they have the right amount of stock to meet customer needs without overstocking or understocking, which can lead to financial losses.

**Resource Allocation:** Businesses can allocate resources more effectively when they have a clear understanding of expected sales. This includes staffing levels, marketing budgets, production schedules, and more.

**Financial Planning:** Sales predictions play a significant role in financial planning and budgeting. They help businesses set revenue targets, allocate funds appropriately, and make strategic decisions about investments and expenses.

**Marketing Strategies:** Predicting sales helps in devising effective marketing strategies. Businesses can tailor their promotional activities, pricing strategies, and product launches based on anticipated sales volumes and customer behavior.

**Risk Management:** Accurate sales forecasts assist in identifying potential risks and opportunities. By understanding market trends and consumer behavior, businesses can proactively mitigate risks and capitalize on opportunities.

**Performance Evaluation:** Sales predictions provide a benchmark for evaluating business performance. By comparing actual sales to predicted sales, businesses can assess their effectiveness in various areas and make adjustments as needed.

# **Data Source**
 The dataset is collected from the Kaggle website "Big Sales Data.csv"
 https://www.kaggle.com/code/tamalkoley/bigmart-sales-data-prediction/input

# **Import Libaries**
Importing the necessary libaries for the project
"""

import pandas as pd

"""# **Import Data**
Import the data
"""

df=pd.read_csv('Big Sales Data.csv')

df.head()

df.tail()

df.info()

df.columns

"""# **Describe Data**
Describing the parameters for the project
"""

df.describe()

df.describe(include='all')

df.shape

df.nunique()

"""# **Data Visualization**
Visualizing the data
"""

df.hist()

import seaborn as sns
sns.pairplot(df)

import matplotlib.pyplot as plt
plt.scatter(y_test,y_pred)
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual Price vs Predicted Price")
plt.show()

df.isna().sum()

"""# **Data Preprocessing**
Preprocessing the data
"""

df['Item_Weight'].fillna(df.groupby(['Item_Type'])['Item_Weight'].transform('mean'),inplace=True)

df.info()

df[['Item_Identifier']].value_counts()

df[['Item_Fat_Content']].value_counts()

# Replace wrong values with correct values
df.replace({'Item_Fat_Content':{'LF':'Low Fat','reg':'Regular','low fat':'Low Fat'}},inplace=True)

df.replace({'Item_Fat_Content':{'Low Fat':0,'Regular':1}},inplace=True)

df[['Item_Type']].value_counts()

df.replace({'Item_Type':{'Fruits and Vegetables':0,'Snack Foods':0,'Household':1,'Frozen Foods':0,'Dairy':0,'Baking Goods':0,'Canned':0,'Health and Hygiene':1,'Meat':0,'Soft Drinks':0,'Breads':0,'Hard Drinks':0,'Others':2,'Starchy Foods':0,'Breakfast':0,'Seafood':0}},inplace=True)

df[['Item_Type']].value_counts()

df[['Outlet_Identifier']].value_counts()

df.replace({'Outlet_Identifier':{'OUT027':0,'OUT013':1,'OUT049':2,'OUT046':3,'OUT035':4,'OUT045':5,'OUT018':6,'OUT017':7,'OUT010':8,'OUT019':9}},inplace=True)

df[['Outlet_Identifier']].value_counts()

df.replace({'Outlet_Size':{'Small':0,'Medium':1,'High':2}},inplace=True)

df[['Outlet_Size']].value_counts()

df[['Outlet_Location_Type']].value_counts()

df.replace({'Outlet_Location_Type':{'Tier 1':0,'Tier 2':1,'Tier 3':2}},inplace=True)

df[['Outlet_Location_Type']].value_counts()

df.replace({'Outlet_Type':{'Supermarket Type1' :1,'Grocery Store' :0,'Supermarket Type3' :3,'Supermarket Type2' :2}},inplace=True)

df[['Outlet_Type']].value_counts()

df.head()

df.info()

"""# **Define Target Variable (y) and Feature Variables (X)**
Defining the target and feature variables of the dataset

# **Target variable (y)**
"""

y=df['Item_Outlet_Sales']

y.shape

y

"""# **Feature Variables (X)**"""

x=df[['Item_Weight', 'Item_Fat_Content', 'Item_Visibility',
       'Item_Type', 'Item_MRP', 'Outlet_Identifier',
       'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',
       'Outlet_Type']]

x=df.drop(['Item_Identifier','Item_Outlet_Sales'],axis=1)

x.shape

x

"""# **Normalization**
Normalizing the data using StandardScaler() function
"""

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

X_std=df[['Item_Weight','Item_Visibility','Item_MRP','Outlet_Establishment_Year']]

X_std=sc.fit_transform(X_std)

X_std

X[['Item_Weight','Item_Visibility','Item_MRP','Outlet_Establishment_Year']]= pd.DataFrame(X_std,columns=[['Item_Weight','Item_Visibility','Item_MRP','Outlet_Establishment_Year']])

X

"""# **Train Test Split**
Splitting the data into train and test data
"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=2529)

x_train.shape,x_test.shape,y_train.shape,y_test.shape

"""# **Modeling**
Modeling the dataset using Random Forest Regressor
"""

from sklearn.ensemble import RandomForestRegressor
rforest= RandomForestRegressor(random_state=2529)
rforest.fit(x_train,y_train)

"""# **Model Evaluation**
Evaluating the model using variuos metrics such as r2_score,mean_squared_error,mean_absolute_error, F1 Score
"""

from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error

mean_squared_error(y_test,y_pred)

mean_absolute_error(y_test,y_pred)

r2_score(y_test,y_pred)

"""# **Prediction**
Output of algorithm after trained on the dataset
"""

y_pred=rforest.predict(x_test)

y_pred.shape

y_pred

import numpy as np

pred = rforest.predict(np.array([[12.300000,0,	0.111904,	0,	33.9874,	7,2007	,1	,1,	1]]))[0]
print(pred)
print(f"Sales Value is between {pred-714.42} and {pred+714.42}")

"""# **Explaination**
Big sales prediction, also known as sales forecasting or sales prediction modeling, is the process of using historical sales data, market trends, and other relevant factors to forecast future sales volumes accurately. Here's an explanation of how it typically works:

1. **Data Collection**: The first step in sales prediction involves gathering relevant data. This includes historical sales data, such as past revenues, units sold, and other relevant metrics. Additionally, businesses may collect data on external factors that influence sales, such as economic indicators, seasonality, competitor activities, and marketing campaigns.

2. **Data Preprocessing**: Once the data is collected, it needs to be cleaned and preprocessed to ensure its quality and relevance. This may involve removing outliers, handling missing values, and transforming the data into a format suitable for analysis.

3. **Feature Selection**: In this step, relevant features or variables that affect sales are identified. These features could include factors such as price, promotions, seasonality, customer demographics, and macroeconomic indicators.

4. **Model Selection**: Various statistical and machine learning models can be used for sales prediction, depending on the complexity of the problem and the nature of the data. Commonly used models include time series analysis methods (such as ARIMA and exponential smoothing), regression analysis, machine learning algorithms (such as linear regression, decision trees, random forests, and neural networks), and ensemble methods.

5. **Model Training**: Once a suitable model is selected, it is trained using historical sales data and relevant features. During training, the model learns the relationships between the input variables (features) and the target variable (sales) to make predictions.

6. **Validation and Testing**: After training the model, it needs to be validated and tested to assess its performance. This involves splitting the data into training and testing sets, where the training set is used to train the model, and the testing set is used to evaluate its performance. Techniques such as cross-validation and holdout validation are commonly used for this purpose.

7. **Evaluation and Optimization**: The performance of the model is evaluated using metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), or Root Mean Squared Error (RMSE). Based on the evaluation results, the model may be refined or optimized by adjusting parameters, feature selection, or trying different algorithms.

8. **Deployment and Monitoring**: Once the model is trained and validated, it can be deployed in a real-world setting to make sales predictions. It is important to continuously monitor the model's performance and update it periodically with new data to ensure its accuracy and relevance over time.

Overall, big sales prediction involves a combination of data analysis, statistical modeling, and machine learning techniques to forecast future sales volumes accurately, providing valuable insights for decision-making and business planning.
"""

